{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adfd7e93",
   "metadata": {},
   "source": [
    "This tutorial will demonstrate how to:\n",
    "- fit tuning curves given behavioral labels (e.g. position)\n",
    "- perform state-space decoding in the fashion of [Denovellis et. al. (2021)](https://elifesciences.org/articles/64505). It gives the posterior probability of the *label* and the *dynamics type* (they call it continuous and discrete variable, repsectively). \n",
    "    - *dynamics type* specifies the temporal prior of the label. When the dynamics type is *continuous*, the temporal prior of the label is a gaussian random walk, with a movement variance specified by the user. When the dynamics type is *fragmented*, the temporal prior of the label is uniform across all possible bins.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317d29a0",
   "metadata": {},
   "source": [
    "# import  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "134ef56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f267e10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import poor_man_gplvm as pmg\n",
    "import poor_man_gplvm.plot_helper as ph\n",
    "import pynapple as nap\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4eebc3",
   "metadata": {},
   "source": [
    "# Load the data (ignore this section and replace with your own data)\n",
    "Some words on data preprocessing. We highly recommend [pynapple](https://pynapple.org/) as an entry point for neural data analysis in Python. They wrap around numpy objects but provide additional useful functionalities like restricting to time intervals, aligning to common time stamps, and turn spike times into counts. Essentially, for this tutorial, we need: \n",
    "- *spk_times*: pynapple TsGroup, obtained from a list of spike times (from the entire recording) for each unit.\n",
    "- *position_tsdf*: pynapple TsdFrame, obtained from an array of (n_time, n_columns), timestamps, and column names. Each column is one behavior label we will decode (doesn't have to be position).\n",
    "- *behavior_ep*: pynapple IntervalSet, obtained from arrays of start and end times of the behavior epoch when tuning curve is computed. \n",
    "- *speed_tsd* (optional): pynapple Tsd, obtained from an array of (n_time,) and timestamps. Here it is used for subselecting the locomotion epochs to include in the tuning curve computation. \n",
    "\n",
    "For the replay analysis later, we also need:\n",
    "- *ep_full*: pynapple IntervalSet, for the whole recording where replay will be identified \n",
    "- *ep_nrem*: pynapple IntervalSet, for the non-REM episodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee84f1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append('../../poor_gplvm/code')\n",
    "import preprocess_roman_tmaze as preprt\n",
    "\n",
    "\n",
    "\n",
    "data_dir_full = preprt.db_roman.iloc[0]['data_dir_full']\n",
    "\n",
    "prep_res = nap.load_folder(os.path.join(data_dir_full, \"derivatives\"))  \n",
    "\n",
    "\n",
    "spk_times = prep_res[\"spk_times\"]\n",
    "ripple_intervals = prep_res[\"ripple_intervals\"]\n",
    "position_tsdf = prep_res[\"position_tsdf\"]\n",
    "behavior_ep = prep_res['behavior_ep']\n",
    "\n",
    "\n",
    "behavior_ep = prep_res['behavior_ep']\n",
    "speed_tsd = prep_res['speed_tsd']\n",
    "\n",
    "# epochs for replay analysis\n",
    "ep_full = prep_res['full_ep']\n",
    "ep_nrem = prep_res['sleep_state_intervals_NREMepisode']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbadabc",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddd339c",
   "metadata": {},
   "source": [
    "## turn spike train into a matrix (TsdFrame, n_time x n_neuron) of spike counts \n",
    "Optional: use a mask to subselect only the pyramidal cells. This is easy if the relevant mask, e.g. *is_pyr* (whether it is a pyramidal cell) is stored as a metadata in the TsGroup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6c82d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_times_pyr=spk_times[spk_times['is_pyr']]\n",
    "spk_mat = spk_times_pyr.count(0.1,ep=behavior_ep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3eed73",
   "metadata": {},
   "source": [
    "## prepare the labels and hyperparameters\n",
    "### labels\n",
    "In the paradigm of spatial navigation, the `label_d` can be time series of:\n",
    "- linearized positions \n",
    "- 2D positions \n",
    "- [choice port ID](https://www.nature.com/articles/s41586-024-08397-7)\n",
    "- linearized positions + direction\n",
    "- 2D positions + direction\n",
    "\n",
    "Indeed, in contrast to existing libraries of spatial decoding, we allow for arbitrary numbers of label dimension (up to memory constraint, so practically if one is already using 2D positions, the extra dimensions should not have too many discretized bins). \n",
    "\n",
    "Even for a linearizeable maze like the alternating T-maze, I personally still prefer using the 2D positions as labels. Whereas for a linear track, I would use the 1D position + direction, although 2D could give a subtler picture as hinted by [Zutshi et. al. (2025)](https://www.nature.com/articles/s41586-024-08397-7).\n",
    "\n",
    "\n",
    "### Hyperparameters\n",
    "- `label_bin_size`: binsize for discretizing the labels. \n",
    "- `smooth_std`: the standard deviation of the Gaussian kernel for smoothing the tuning curves. If None then no smoothing.\n",
    "- `occupancy_threshold`: the occupancy threshold (in seconds) for the label bin to be considered valid. \n",
    "\n",
    "All of the above can be either: 1) a single number that apply to all the dimensions; 2) a list of value per dimension; and 3) for multiple mazes, a dictionary of {maze_key: val}, where val can be 1) or 2). This means for multiple mazes different labels can be provided for different mazes.\n",
    "\n",
    "Here we will demonstrate the more general syntax assuming multiple mazes, but know that it can be simplified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77c36ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_d= {} \n",
    "label_d['familiar']=position_tsdf[['x','y']].restrict(behavior_ep[0]) # The restrict limit the x y coordinates to the first behavior epoch\n",
    "\n",
    "ep_d={}\n",
    "ep_d['familiar'] = speed_tsd.restrict(behavior_ep[0]).threshold(5).time_support\n",
    "\n",
    "label_bin_size_d = {}\n",
    "label_bin_size_d['familiar'] =  3.\n",
    "\n",
    "smooth_std_d = {}\n",
    "smooth_std_d['familiar'] = 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3e6b41",
   "metadata": {},
   "source": [
    "## below is if there's a second novel linear maze, with time_window given by `behavior_ep[1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c884b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# novel_lin=position_tsdf[['lin']].restrict(behavior_ep[1])\n",
    "\n",
    "# novel_lin_dir = novel_lin.derivative() > 0\n",
    "\n",
    "# beh_tsdf_novel=nap.TsdFrame(d=np.stack([novel_lin.d,novel_lin_dir.d.astype(int)],axis=1),t=novel_lin.t,columns=['lin','dir'])\n",
    "\n",
    "# label_d['novel'] = beh_tsdf_novel\n",
    "\n",
    "# speed_tsd_novel = np.abs(novel_lin.derivative())\n",
    "\n",
    "# ep_d['novel'] = speed_tsd_novel.threshold(5).time_support\n",
    "\n",
    "\n",
    "\n",
    "# label_bin_size_d['novel'] = [3.,1.]\n",
    "\n",
    "# smooth_std_d['novel'] = [3,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1428ae44",
   "metadata": {},
   "source": [
    "# compute tuning curves\n",
    "Tuning curves are computed by: 1) discretize the multi-dimensional labels into bins; 2) get occupancy of each bin; 3) drop the low occupancy bins; 4) compute the spike counts emitted within each bin; 5) smooth the occupancy and spike counts using a Gaussian kernel; 6) FR = count_smoothed / occupancy_smoothed, in Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24a5d863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'poor_man_gplvm' from '/mnt/home/szheng/projects/poor-man-GPLVM/poor_man_gplvm/__init__.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(pmg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79bb4528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[get_tuning] maze=familiar: grid_shape=(29, 28), n_neurons=422, dt=0.1000s, n_valid_time=8930, n_occupied_bins=306\n"
     ]
    }
   ],
   "source": [
    "tuning_res = pmg.get_tuning_supervised(\n",
    "    spk_mat,# nap.TsdFrame, n_time x n_neuron\n",
    "    label_d,\n",
    "    ep=ep_d,                   # nap.IntervalSet (optional)\n",
    "    label_bin_size=label_bin_size_d,          # cm\n",
    "    smooth_std=smooth_std_d,              # cm, Gaussian kernel std\n",
    "    occupancy_threshold=0.1,     # seconds\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2746ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['tuning', 'occupancy', 'occupancy_smth', 'spk_count', 'spk_count_smth', 'bin_edges', 'bin_centers', 'label_grid_centers', 'grid_shape', 'label_dim_names', 'neuron_names', 'occupied_mask', 'valid_flat_mask', 'dt', 'smoothing_matrix', 'n_valid_timepoints', 'tuning_flat', 'occupancy_flat', 'occupancy_smth_flat', 'spk_count_flat', 'spk_count_smth_flat', 'coord_to_flat_idx', 'flat_idx_to_coord'])\n"
     ]
    }
   ],
   "source": [
    "print(tuning_res.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a71fd5",
   "metadata": {},
   "source": [
    "Some important keys of the `tuning_res`:\n",
    "- `tuning`: Dictionary {maze_key: tuning_per_maze}; tuning_per_maze: xarray.DataArray, (n_label_dim_1_bin, n_label_dim_2_bin, ..., n_neuron). This representation is easier for plotting\n",
    "- `tuning_flat`: array of (n_label_bin_total, n_neuron). All valid bins are concatenated together. This representation is easier for decoders\n",
    "- `coord_to_flat_idx`: Dictionary {maze_key: pandas.Series}, the index are the label bin centers and the value is the index within the flattened label bins.\n",
    "- `flat_idx_to_coord`: Pandas.DataFrame, index is the index within the flattened label bins, and columns are maze key plus all the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e347bd",
   "metadata": {},
   "source": [
    "example spatial tuning of a neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a5ca29c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x154c3a184fb0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuning_res['tuning']['familiar'].isel(neuron=0).T.plot() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b58e769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'familiar': x          y        \n",
       " 3.550231   4.755008       0\n",
       "            10.755008      1\n",
       "            13.755008      2\n",
       "            79.755008      3\n",
       "            82.755008      4\n",
       "                        ... \n",
       " 87.550231  46.755008    301\n",
       "            49.755008    302\n",
       "            79.755008    303\n",
       "            82.755008    304\n",
       "            85.755008    305\n",
       " Length: 306, dtype: int64}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_res['coord_to_flat_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa51fa30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maze</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>familiar</td>\n",
       "      <td>3.550231</td>\n",
       "      <td>4.755008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>familiar</td>\n",
       "      <td>3.550231</td>\n",
       "      <td>10.755008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>familiar</td>\n",
       "      <td>3.550231</td>\n",
       "      <td>13.755008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>familiar</td>\n",
       "      <td>3.550231</td>\n",
       "      <td>79.755008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>familiar</td>\n",
       "      <td>3.550231</td>\n",
       "      <td>82.755008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              maze         x          y\n",
       "flat_idx                               \n",
       "0         familiar  3.550231   4.755008\n",
       "1         familiar  3.550231  10.755008\n",
       "2         familiar  3.550231  13.755008\n",
       "3         familiar  3.550231  79.755008\n",
       "4         familiar  3.550231  82.755008"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_res['flat_idx_to_coord'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf884e14",
   "metadata": {},
   "source": [
    "# Replay analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbacb71f",
   "metadata": {},
   "source": [
    "## preprocessing for replay analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55070ac9",
   "metadata": {},
   "source": [
    "### Identify population burst events\n",
    "We bin spikes finely (`bin_size`,default 2ms), average across neurons (pyramidal cells), lightly smooth (`smooth_std`, default 7.5ms), z-score, identify the windows where the firing rate reachs beyond 3 standard deviations `z_thresh`, and extend both sides of the window back to the mean. The events are filtered by a `min_duration` and `max_duration`.\n",
    "\n",
    "- `ep`: pynapple IntervalSet, time epochs where the population burst events are to be identified\n",
    "- `threshold_ep`: pynapple IntervalSet, time epochs where the mean and standard deviation of firing rates are computed. Here we choose only the non-REM epochs.\n",
    "- `force_reload`: whether to re-compute if the file already exists\n",
    "- `dosave`: whether to save\n",
    "- `return_population_rate`: whether to return the population firing rate, since it can be a long time series\n",
    "\n",
    "Can optionally supply `ripple_intervals` (pynapple IntervalSet) so that the detected PBE is aware of how many sharp wave ripples are contained within. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf8e936a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/home/szheng/ceph/ad/roman_data/e13/e13_26m1/e13_26m1_210913/py_data/pbe.p exists; loading---\n",
      "CPU times: user 97.1 ms, sys: 6.88 ms, total: 104 ms\n",
      "Wall time: 150 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get pbe\n",
    "import poor_man_gplvm.post_fit_workflow.get_event_windows as gew\n",
    "\n",
    "is_pyr = spk_times['is_pyr'] # assuming is_pyr is in the metadata of spk_times; otherwise a boolean array of length n_neuron would work\n",
    "spk_times_pyr=spk_times[is_pyr] \n",
    "pbe_save_dir=os.path.join(data_dir_full,'py_data') # replace with the directory you like!\n",
    "save_fn='pbe.p'#'pbe_wake_and_sleep_all.p'#\n",
    "\n",
    "\n",
    "pbe_res=gew.detect_population_burst_event(spk_times_pyr, mask=None, ep=ep_full,threshold_ep=prep_res['sleep_state_intervals_NREMepisode'], bin_size=0.002, smooth_std=0.0075, \n",
    "                                 z_thresh=3.0, min_duration=0.05, max_duration=0.5,\n",
    "                                 ripple_intervals=None,force_reload=False,dosave=False,save_dir=pbe_save_dir,return_population_rate=False,save_fn=save_fn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e21387a",
   "metadata": {},
   "source": [
    "### Bin spikes\n",
    "To work with data grouped by events / trials, we use a helper function that takes in `spk_times` (pynapple TsGroup) and `binsize` (default 0.02 s) and bin the spikes into two formats: `spike_tensor` and `spike_mat`, and return other useful information. The returned Dictionary has the following keys:\n",
    "\n",
    "- `spike_tensor`: array of shape (n_event, n_time_max, n_neuron), binned spikes seperated by event; all events padded to the same length.  \n",
    "- `spike_mat`: TsdFrame of shape (n_time_concat, n_neuron), concatenated spike counts\n",
    "- `time_l`: time stamps, (n_time_concat,) \n",
    "- `event_index_per_bin`: index of the event at each concatenated time bin, (n_time_concat,)\n",
    "- `mask`: mask showing the padding for the tensor; (n_event, n_time_max, 1); True means the time bin is in the event and not padded\n",
    "- `time_per_trial`: List of arrays (unequal lengths), each containing the time stamps of each event \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c5dea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import poor_man_gplvm.trial_analysis as tri\n",
    "binsize = 0.02\n",
    "spk_tensor_res=tri.bin_spike_train_to_trial_based(spk_times_pyr,pbe_res['event_windows'],binsize=binsize) # here we use the pyramidal cells only but you could also do all cells; just need to match with the tuning curves!\n",
    "\n",
    "spk_tensor=spk_tensor_res['spike_tensor']\n",
    "spk_mat_pbe=spk_tensor_res['spike_mat']\n",
    "tensor_pad_mask=spk_tensor_res['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a23f0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor format shape (n_event, n_time_max, n_neuron) (5400, 25, 422)\n",
      "Matrix format shape (n_time_concat, n_neuron) (30532, 422)\n",
      "Tensor pad mask shape (n_event, n_time_max, 1) (5400, 25, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Tensor format shape (n_event, n_time_max, n_neuron)',spk_tensor.shape)\n",
    "print('Matrix format shape (n_time_concat, n_neuron)',spk_mat_pbe.shape)\n",
    "print('Tensor pad mask shape (n_event, n_time_max, 1)',tensor_pad_mask.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90fa6d3",
   "metadata": {},
   "source": [
    "# First question - whether an event is better-explained by the tuning templates than chance (goodness-of-fit, \"on-manifold\"ness)\n",
    "For the first question we measure the model fit by the marginal likelihood of the Naive Bayes decoder. There is no temporal prior. It is asking whether the population vectors from one event lie on the manifold of tuning curves, ignoring any question about temporal sequenceness. \n",
    "\n",
    "We use two shuffles to answer this question:\n",
    "- *Neuron ID shuffle*: check whether the Neuron - tuning curve association is needed for the model fit\n",
    "- *Circular shuffle*: check whether the **co-activity** is driving the model fit (rather than single neuron firing statistics)\n",
    "\n",
    "Usually the *circular shuffle* test is harder to pass. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0220e034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[shuffle_test_naive_bayes_marginal_l] chunk: decode true\n",
      "[shuffle_test_naive_bayes_marginal_l] chunk: init shuffle stats\n",
      "[shuffle_test_naive_bayes_marginal_l] chunk: decode shuffles (tqdm)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:49<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[shuffle_test_naive_bayes_marginal_l] chunk: quantiles + significance\n",
      "[shuffle_test_naive_bayes_marginal_l] chunk: expand is_sig_overall to time bins\n",
      "saved: ./supervised_shuffle.p.pkl\n"
     ]
    }
   ],
   "source": [
    "import poor_man_gplvm.post_fit_workflow.shuffle_test_decoding as shuf\n",
    "\n",
    "dt = binsize # binsize during PBEs as was used before, 20ms default\n",
    "gain = 1 # multiply the tuning by a scalar to reflect possible change in firing rate, default 1\n",
    "save_dir='./' # replace\n",
    "save_fn='supervised_shuffle.p' # replace\n",
    "\n",
    "tuning_flat = tuning_res['tuning_flat']\n",
    "flat_idx_to_coord = tuning_res['flat_idx_to_coord']\n",
    "event_index_per_bin = spk_tensor_res['event_index_per_bin']\n",
    "spk_mat_pbe = spk_tensor_res['spike_mat']\n",
    "\n",
    "shuffle_res = shuf.shuffle_test_naive_bayes_marginal_l(\n",
    "    spk_mat_pbe,\n",
    "    event_index_per_bin,\n",
    "    tuning=tuning_flat,\n",
    "    n_shuffle=100,\n",
    "    sig_thresh=0.95,\n",
    "    seed=0,\n",
    "    decoding_kwargs={'dt': dt, 'gain': gain, 'n_time_per_chunk': 20000},\n",
    "    dosave=True,\n",
    "    force_reload=False,\n",
    "    save_dir=save_dir,\n",
    "    save_fn=save_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ec8e0e",
   "metadata": {},
   "source": [
    "# Second question: is there spatially coherent content and quantify the metrics of spatial replays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f538dfb8",
   "metadata": {},
   "source": [
    "For this question, we use the state-space decoder from [Denovellis et. al. (2021)](https://elifesciences.org/articles/64505) (we only include the *continuous* and *fragmented* dynamics, lumping *stationary* into *continuous*). The probability of *continuous* dynamics gives a measure for how smoothly the decoded trajectory evolve as opposed to jumping around. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2bcedce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import poor_man_gplvm.supervised_analysis.decoder_supervised as decoder_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "173816aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movement_variance_d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmovement_variance_d\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'movement_variance_d' is not defined"
     ]
    }
   ],
   "source": [
    "movement_variance_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00ea336b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movement_variance_d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# run decoding\u001b[39;00m\n\u001b[1;32m      2\u001b[0m res \u001b[38;5;241m=\u001b[39m decoder_supervised\u001b[38;5;241m.\u001b[39mdecode_with_dynamics(\n\u001b[1;32m      3\u001b[0m     spk_tensor,\n\u001b[1;32m      4\u001b[0m     tuning_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuning_flat\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m     time_l \u001b[38;5;241m=\u001b[39m spk_tensor_res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_l\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      6\u001b[0m     tensor_pad_mask\u001b[38;5;241m=\u001b[39mspk_tensor_res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m     coord_to_flat_idx\u001b[38;5;241m=\u001b[39mtuning_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoord_to_flat_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      8\u001b[0m     flat_idx_to_coord\u001b[38;5;241m=\u001b[39mtuning_res\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflat_idx_to_coord\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),  \u001b[38;5;66;03m# set None if you don't want maze-splitting\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     dt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m,\n\u001b[1;32m     10\u001b[0m     gain\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m---> 11\u001b[0m     continuous_transition_movement_variance\u001b[38;5;241m=\u001b[39m\u001b[43mmovement_variance_d\u001b[49m,\n\u001b[1;32m     12\u001b[0m     p_move_to_jump\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m,\n\u001b[1;32m     13\u001b[0m     p_jump_to_move\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m,\n\u001b[1;32m     14\u001b[0m     n_time_per_chunk\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20000\u001b[39m,\n\u001b[1;32m     15\u001b[0m     likelihood_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m     16\u001b[0m     observation_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoisson\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'movement_variance_d' is not defined"
     ]
    }
   ],
   "source": [
    "# run decoding\n",
    "res = decoder_supervised.decode_with_dynamics(\n",
    "    spk_tensor,\n",
    "    tuning_res[\"tuning_flat\"],\n",
    "    time_l = spk_tensor_res['time_l'],\n",
    "    tensor_pad_mask=spk_tensor_res['mask'],\n",
    "    coord_to_flat_idx=tuning_res[\"coord_to_flat_idx\"],\n",
    "    flat_idx_to_coord=tuning_res.get(\"flat_idx_to_coord\", None),  # set None if you don't want maze-splitting\n",
    "    dt=0.02,\n",
    "    gain=1.0,\n",
    "    continuous_transition_movement_variance=movement_variance_d,\n",
    "    p_move_to_jump=0.02,\n",
    "    p_jump_to_move=0.02,\n",
    "    n_time_per_chunk=20000,\n",
    "    likelihood_scale=1.0,\n",
    "    observation_model=\"poisson\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91e3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxnew2",
   "language": "python",
   "name": "jaxnew2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
